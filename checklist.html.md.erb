---
title: Upgrade Preparation Checklist for Enterprise PKS v1.5
owner: PKS
---

This topic serves as a checklist for preparing to upgrade <%= vars.product_full %> v1.4 to
<%= vars.product_full %> v1.5.

This topic contains important preparation steps that you must follow before beginning your upgrade.
Failure to follow these instructions may jeopardize your existing deployment data and cause the
upgrade to fail.

After completing the steps in this topic, you can continue to [Upgrading <%= vars.product_short %>](upgrade-pks.html).
If you are upgrading <%= vars.product_short %> for environments using vSphere with NSX-T, continue to
[Upgrading <%= vars.product_short %> with NSX-T](upgrade-pks-nsxt.html).

##<a id='backup'></a>Back Up Your <%= vars.product_short %> Deployment

We recommend backing up your <%= vars.product_short %> deployment before upgrading, to restore in case of failure.

**If you are upgrading <%= vars.product_short %> for environments using vSphere with NSX-T**, back up your environment
using the procedures in the following topics:

- [Backup <%= vars.product_short %>](backup-and-restore.html)
- <a href="https://docs.vmware.com/en/VMware-NSX-T/2.1/com.vmware.nsxt.admin.doc/GUID-A0B3667C-FB7D-413F-816D-019BFAD81AC5.html">Backup NSX-T</a>
- <a href="https://kb.vmware.com/s/article/2149237">Backup vCenter</a>
<p class="note"><strong>Note</strong>: If you choose not to back up <%= vars.product_short %>, NSX-T, or vCenter, we recommend backing up the NSX-T and NSX-T Container Plugin (NCP) logs.</p>

**If you are upgrading <%= vars.product_short %> for any other IaaS**, back up the the existing <%= vars.product_short %> control plane. For more
information, see [Backing Up and Restoring <%= vars.product_short %>](https://docs.pivotal.io/pks/1-3/backup-and-restore.html).

##<a id='review-changes'></a> Review Changes in <%= vars.product_short %> v1.5

Review the [Release Notes](release-notes.html) for <%= vars.product_short %> v1.5.

##<a id='configure-psp-bindings'></a> Configure RBAC for PSPs

<%= vars.product_short %> includes the Pod Security Policies (PSPs) security feature.
For more information about PSPs in <%= vars.product_short %>,
see the [Pod Security Policy](./pod-security-policy.html).

When you install or upgrade <%= vars.product_short %>, PSPs are not enabled by default.
If you want to enable PSPs for a new or existing cluster,
you must define the necessary RBAC objects in a role and role binding
and PSP before you deploy the cluster. If you do not define these objects
users will not be able to access the Kubernetes cluster after deployment.
See [Enabling PSPs](./pod-security-policy.html#psp-enable) for more information

 <%= vars.product_short %> provides a PSP named `pks-restricted` that you use.
You can define your own PSPs or use one of the cluster roles already in the system.
At a minimum, you need to define the proper cluster role binding so that users
can access a cluster with PSPs enabled.
See [Configuring PSP for Developers to Use](./pod-security-policy.html#psp-config) for more information.

##<a id='configure-oidc-prefixes'></a> Configure OIDC Prefixes

In <%= vars.product_short %> v1.5, you can configure prefixes for OpenID Connect (OIDC) users
and groups. You can use these prefixes to avoid name conflicts with existing Kubernetes system users.
Pivotal recommends adding prefixes to ensure OIDC users and groups
do not gain unintended privileges on clusters. For instructions about configuring OIDC prefixes,
see the [Configure OpenID Connect](./installing-pks-vsphere.html#configure-oidc) section
in the _Installing_ topic for your IaaS.

If you add OIDC prefixes you must manually change any existing roles and role bindings
that bind to a username or group.
If you do not change your role and role bindings, developers cannot access Kubernetes clusters.
For instructions about creating a role and role binding,
see [Managing Cluster Access and Permissions](./manage-cluster-permissions.html).

##<a id='understand-upgrades'></a> Understand What Happens During <%= vars.product_short %> Upgrades

Review [What Happens During <%= vars.product_short %> Upgrades](understanding-upgrades.html), and evaluate your workload
capacity and uptime requirements.

##<a id='resource-usage'></a> View Workload Resource Usage

View your workload resource usage in Dashboard. For more information, see
[Accessing Dashboard](access-dashboard.html).

If workers are operating too close to their capacity, the upgrade can fail. To prevent workload
downtime during a cluster upgrade, we recommend running your workload on at least three
worker VMs, using multiple replicas of your workloads spread across those VMs. For more
information, see [Maintaining Workload Uptime](maintain-uptime.html).

If your clusters are near capacity for your existing infrastructure, we recommend scaling up your
clusters before you upgrade. Scale up your cluster by running `pks resize` or create a cluster
using a larger plan. For more information, see [Scaling Existing Clusters](scale-clusters.html).

##<a id='verify-k8s-health'></a> Verify Health of Kubernetes Environment

Verify that your Kubernetes environment is healthy. To verify the health of your Kubernetes
environment, see [Verifying Deployment Health](verify-health.html#k8s).

##<a id='review-vsphere-nsxt'></a> Verify NSX-T Configuration (vSphere with NSX-T Only)

If you are upgrading <%= vars.product_short %> for environments using vSphere with NSX-T, perform the following steps:

1. Verify that the vSphere datastores have enough space.
1. Verify that the vSphere hosts have enough memory.
1. Verify that there are no alarms in vSphere.
1. Verify that the vSphere hosts are in a good state.
1. Verify that NSX Edge is configured for high availability using Active/Standby mode.
  <p class="note"><strong>Note</strong>: Workloads in your Kubernetes cluster are unavailable while
  the NSX Edge nodes run the upgrade unless you configure NSX Edge for high availability. For more
  information, see the <a href="./nsxt-prepare-env.html#nsx-edge-ha">Configure NSX Edge for High Availability (HA)</a>
section of <em>Preparing NSX-T Before Deploying <%= vars.product_short %></em>.</p>

##<a id='clean-up'></a> Clean Up Failed Kubernetes Clusters

Clean up previous failed attempts to delete PKS clusters with the PKS Command Line Interface
(PKS CLI) by performing the following steps:

1. View your deployed clusters by running the following command:

    ```
    pks clusters
    ```

    If the `Status` of any cluster displays as `FAILED`, continue to the next step. If no cluster
    displays as `FAILED`, no action is required. Continue to the next section.

1. Perform the procedures in
[Cannot Re-Create a Cluster that Failed to Deploy](troubleshoot-issues.html#cluster-recreate-fails)
to clean up the failed BOSH deployment.

1. View your deployed clusters again by running `pks clusters`. If any clusters remain in a `FAILED`
state, contact PKS Support.

##<a id='unique-hostname'></a> Verify Kubernetes Clusters Have Unique External Hostnames

Verify that existing Kubernetes clusters have unique external hostnames by checking for multiple
Kubernetes clusters with the same external hostname. Perform the following steps:

1. Log in to the PKS CLI. For more information, see
[Logging in to <%= vars.product_short %>](login.html). You must log in with an account that has the
UAA scope of `pks.clusters.admin`. For more information about UAA scopes, see
[Managing <%= vars.product_short %> Admin Users with UAA](manage-users.html).

1. View your deployed PKS clusters by running the following command:

    ```
    pks clusters
    ```
1. For each deployed cluster, run `pks cluster CLUSTER-NAME` to view the details of the cluster.
For example:

    <pre class="terminal">
    $ pks cluster my-cluster
    </pre>
    Examine the output to verify that the `Kubernetes Master Host` is unique for each cluster.

##<a id='pks-proxy'></a> Verify PKS Proxy Configuration

Verify your current PKS proxy configuration by performing the following steps:

1. Check whether an existing proxy is enabled:
    1. Log in to Ops Manager.
    1. Click the **VMware Enterprise PKS** tile.
    1. Click **Networking**.
    1. If **HTTP/HTTPS Proxy** is **Disabled**, no action is required. Continue to the next section.
       If **HTTP/HTTPS Proxy** is **Enabled**, continue to the next step.

1. If the existing **No Proxy** field contains any of the following values, or you plan to add any
of the following values, contact PKS Support:
	* `localhost`
	* Hostnames containing dashes, such as `my-host.mydomain.com`

##<a id='check-poddisruptionbudget-value'></a> Check PodDisruptionBudget Value

<%= vars.product_short %> upgrades can run without ever completing if any Kubernetes app has a `PodDisruptionBudget`
with `maxUnavailable` set to `0`. To ensure that no apps have a `PodDisruptionBudget` with
`maxUnavailable` set to `0`, perform the following steps:

1. Use the Kubernetes CLI, `kubectl`, to verify the `PodDisruptionBudget` as the cluster
administrator. Run the following command:

    ```
    kubectl get poddisruptionbudgets --all-namespaces
    ```

1. Examine the output. Verify that no app displays `0` in the `MAX UNAVAILABLE` column.

## <a id="configure-node-drain"></a> Configure Node Drain Behavior

During the <%= vars.product_tile %> tile upgrade process, worker nodes are cordoned and drained.
Workloads can prevent worker nodes from draining and cause the upgrade to fail or hang.

To prevent hanging cluster upgrades, you can use the PKS CLI to configure the default node drain behavior.
The new default behavior takes effect during the next upgrade,
not immediately after configuring the behavior.

<p class="note"> You can also configure node drain behavior in the <%= vars.product_tile %> tile.
For information about configuring default node drain behavior in
the <%= vars.product_tile %> tile,
see <a href="./troubleshoot-issues.html#upgrade-drain-hangs">Worker Node Hangs Indefinitely</a>
in <i>Troubleshooting</i>.</p>

To configure default node drain behavior, do the following:

1. View the current node drain behavior by running the following command:

    ```
    pks cluster CLUSTER-NAME --details
    ```

    Where `CLUSTER-NAME` is the name of you cluster.
    <br><br>
    For example:
    <pre class="terminal">$ pks cluster my-cluster --details <br>
      Name:                     my-cluster
      Plan Name:                small
      UUID:                     f55ed6c4-c0a7-451d-b735-56c89fdb2ad7
      Last Action:              CREATE
      Last Action State:        succeeded
      Last Action Description:  Instance provisioning completed
      Kubernetes Master Host:   my-cluster.pks.local
      Kubernetes Master Port:   8443
      Worker Nodes:             3
      Kubernetes Master IP(s):  10.196.219.88
      Network Profile Name:
      Kubernetes Settings Details:
        Set by Cluster:
        Kubelet Node Drain timeout (mins)            (kubelet-drain-timeout):               10
        Kubelet Node Drain grace-period (mins)       (kubelet-drain-grace-period):          10
        Kubelet Node Drain force                     (kubelet-drain-force):                 true
        Set by Plan:
        Kubelet Node Drain force-node                (kubelet-drain-force-node):            true
        Kubelet Node Drain ignore-daemonsets         (kubelet-drain-ignore-daemonsets):     true
        Kubelet Node Drain delete-local-data         (kubelet-drain-delete-local-data):     true
      </pre>

1. Configure the default node drain behavior by running the following command:

    ```
    pks update-cluster CLUSTER-NAME FLAG
    ```

    Where:
    + `CLUSTER-NAME` is the name of your cluster.
    + `FLAG` is an action flag for updating the node drain behavior.

    For example:
    <pre class="terminal">$ pks update-cluster my-cluster --kubelet-drain-timeout 1 --kubelet-drain-grace-period 5<br>
      Update summary for cluster my-cluster:
      Kubelet Drain Timeout: 1
      Kubelet Drain Grace Period: 5
      Are you sure you want to continue? (y/n): y
      Use 'pks cluster my-cluster' to monitor the state of your cluster</pre>

    For a list of the available action flags for setting node drain behavior,
    see [pks update-cluster](cli/index.html#update-cluster) in _PKS CLI_.

##<a id='review-azure-worker-role-persmission'></a> Add permission to the role used by the Worker Node Managed Identity

As part of the kubernetes 1.14.5, the worker node requires a Virtual Machine - Read Only permission to be added to the Worker Node Managed Identity. To add the permission do the following :

1. Use the azure-cli to list the roles :

    ```
    az role definition list --custom-role-only true -o json
    ```

1. Get the output of the required role by filtering the list with the `roleName` key.

    ```
    az role definition list --custom-role-only true -o json | jq -r '.[] | select(.roleName=="PKS worker")'
    ```

1. Copy the json to a file and add the permission `"Microsoft.Compute/virtualMachines/read"` to the `Actions` tab. Save your template as `pks_worker_role.json`.

1. Update the role by:

    ```
    az role definition update --role-definition pks_worker_role.json
    ```
